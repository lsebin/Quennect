{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Materials\n",
    "\n",
    "https://github.com/marcotcr/lime?tab=readme-ov-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.ensemble\n",
    "import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "from __future__ import print_function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\celin\\miniconda3\\envs\\videogpt\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import argparse, os\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--layer\", type=float, default=3)\n",
    "    parser.add_argument(\"--hidden\", type=int, default=128)\n",
    "    parser.add_argument(\"--hidden1\", type=int, default=64)\n",
    "    parser.add_argument(\"--hidden2\", type=int, default=32)\n",
    "    parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
    "    parser.add_argument(\"--seed\", type=float, default=42)\n",
    "    parser.add_argument(\"--epoch\", type=int, default=50)\n",
    "    \n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q_vecDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, X_rus, y_rus, train):\n",
    "        self.feature = X_rus\n",
    "        self.target = y_rus\n",
    "        self.train = train\n",
    "\n",
    "  def __len__(self):\n",
    "        return self.target.shape[0]\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        X = self.feature.iloc[[index]]\n",
    "        X = X.to_numpy()\n",
    "        y = self.target.iloc[[index]]\n",
    "        y= y.to_numpy()\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    q_cleaned_old = pd.read_csv('data/data_vectorized_240228.csv')\n",
    "    q_cleaned_old.drop(['ia_status_Facility Study', 'ia_status_Feasibility Study',\n",
    "        'ia_status_IA Executed', 'ia_status_Operational',\n",
    "        'ia_status_System Impact Study', 'Unnamed: 0'], axis = 1, inplace=True)\n",
    "\n",
    "    exempt = []\n",
    "    for col in list(q_cleaned_old.columns):\n",
    "        if q_cleaned_old[col].max() < 1:\n",
    "            exempt.append(col)\n",
    "    q_cleaned_old.drop(columns = exempt, inplace=True)\n",
    "    \n",
    "    # Use batch normalization here - subtract by mean of data + divide by variance\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(q_cleaned_old)\n",
    "    q_cleaned_array = scaler.transform(q_cleaned_old)\n",
    "    q_cleaned = pd.DataFrame(q_cleaned_array, columns=q_cleaned_old.columns)\n",
    "    \n",
    "\n",
    "    features = q_cleaned.drop(['ia_status_Withdrawn'], axis = 1)\n",
    "    target = q_cleaned_old['ia_status_Withdrawn']\n",
    "\n",
    "    seed = 42\n",
    "\n",
    "    rus = RandomUnderSampler(random_state=seed)\n",
    "    X_rus, y_rus= rus.fit_resample(features, target)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_rus, y_rus,\n",
    "                                                            test_size = 0.2,\n",
    "                                                            random_state = seed)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\celin\\git\\Quennect\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.08696952, -0.11717451, -0.42817022, ..., -0.03576319,\n",
       "        -0.02340396, -0.02340396],\n",
       "       [-0.25977336,  1.02335176, -0.42817022, ..., -0.03576319,\n",
       "        -0.02340396, -0.02340396],\n",
       "       [ 0.9498535 ,  0.53455479, -0.42817022, ..., -0.03576319,\n",
       "        -0.02340396, -0.02340396],\n",
       "       ...,\n",
       "       [ 0.08583431, -0.44303915, -0.42817022, ..., -0.03576319,\n",
       "        -0.02340396, -0.02340396],\n",
       "       [ 0.60424583,  0.53455479, -0.42817022, ..., -0.03576319,\n",
       "        -0.02340396, -0.02340396],\n",
       "       [ 0.25863815,  0.20869014, -0.42817022, ..., -0.03576319,\n",
       "        -0.02340396, -0.02340396]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.array(['Not Withdrawn', 'Withdrawn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_year</th>\n",
       "      <th>prop_year</th>\n",
       "      <th>region_CAISO</th>\n",
       "      <th>region_ERCOT</th>\n",
       "      <th>region_ISO-NE</th>\n",
       "      <th>region_MISO</th>\n",
       "      <th>region_NYISO</th>\n",
       "      <th>region_PJM</th>\n",
       "      <th>region_SPP</th>\n",
       "      <th>region_Southeast (non-ISO)</th>\n",
       "      <th>...</th>\n",
       "      <th>util_tsgt</th>\n",
       "      <th>util_ugi</th>\n",
       "      <th>util_unknown</th>\n",
       "      <th>util_upper peninsula power company</th>\n",
       "      <th>util_vea</th>\n",
       "      <th>util_wabash valley power</th>\n",
       "      <th>util_wisconsin electric power company</th>\n",
       "      <th>util_wisconsin public service corporation</th>\n",
       "      <th>util_wolverine power supply cooperative, inc.</th>\n",
       "      <th>util_xcel energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5475</th>\n",
       "      <td>2005.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5476</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5477</th>\n",
       "      <td>2003.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5478</th>\n",
       "      <td>2007.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5479</th>\n",
       "      <td>2001.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5480 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      q_year  prop_year  region_CAISO  region_ERCOT  region_ISO-NE   \n",
       "0     2016.0     2018.0             0             0              0  \\\n",
       "1     2008.0     2011.0             0             0              0   \n",
       "2     2019.0     2023.0             0             0              0   \n",
       "3     2009.0     2010.0             0             0              0   \n",
       "4     2020.0     2023.0             0             0              0   \n",
       "...      ...        ...           ...           ...            ...   \n",
       "5475  2005.0     2007.0             0             0              0   \n",
       "5476  2008.0     2010.0             0             0              0   \n",
       "5477  2003.0     2006.0             0             0              0   \n",
       "5478  2007.0     2007.0             0             0              0   \n",
       "5479  2001.0     2005.0             0             0              0   \n",
       "\n",
       "      region_MISO  region_NYISO  region_PJM  region_SPP   \n",
       "0               0             0           0           0  \\\n",
       "1               0             0           0           0   \n",
       "2               1             0           0           0   \n",
       "3               1             0           0           0   \n",
       "4               1             0           0           0   \n",
       "...           ...           ...         ...         ...   \n",
       "5475            0             0           0           0   \n",
       "5476            0             0           0           0   \n",
       "5477            0             0           0           0   \n",
       "5478            0             0           0           0   \n",
       "5479            0             0           0           0   \n",
       "\n",
       "      region_Southeast (non-ISO)  ...  util_tsgt  util_ugi  util_unknown   \n",
       "0                              1  ...          0         0             0  \\\n",
       "1                              1  ...          0         0             0   \n",
       "2                              0  ...          0         0             0   \n",
       "3                              0  ...          0         0             0   \n",
       "4                              0  ...          0         0             0   \n",
       "...                          ...  ...        ...       ...           ...   \n",
       "5475                           0  ...          0         0             0   \n",
       "5476                           0  ...          0         0             0   \n",
       "5477                           0  ...          0         0             0   \n",
       "5478                           0  ...          0         0             0   \n",
       "5479                           0  ...          0         0             0   \n",
       "\n",
       "      util_upper peninsula power company  util_vea  util_wabash valley power   \n",
       "0                                      0         0                         0  \\\n",
       "1                                      0         0                         0   \n",
       "2                                      0         0                         0   \n",
       "3                                      0         0                         0   \n",
       "4                                      0         0                         0   \n",
       "...                                  ...       ...                       ...   \n",
       "5475                                   0         0                         0   \n",
       "5476                                   0         0                         0   \n",
       "5477                                   0         0                         0   \n",
       "5478                                   0         0                         0   \n",
       "5479                                   0         0                         0   \n",
       "\n",
       "      util_wisconsin electric power company   \n",
       "0                                         0  \\\n",
       "1                                         0   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "...                                     ...   \n",
       "5475                                      0   \n",
       "5476                                      0   \n",
       "5477                                      0   \n",
       "5478                                      0   \n",
       "5479                                      0   \n",
       "\n",
       "      util_wisconsin public service corporation   \n",
       "0                                             0  \\\n",
       "1                                             0   \n",
       "2                                             0   \n",
       "3                                             0   \n",
       "4                                             0   \n",
       "...                                         ...   \n",
       "5475                                          0   \n",
       "5476                                          0   \n",
       "5477                                          0   \n",
       "5478                                          0   \n",
       "5479                                          0   \n",
       "\n",
       "      util_wolverine power supply cooperative, inc.  util_xcel energy  \n",
       "0                                                 0                 0  \n",
       "1                                                 0                 0  \n",
       "2                                                 0                 0  \n",
       "3                                                 0                 0  \n",
       "4                                                 0                 0  \n",
       "...                                             ...               ...  \n",
       "5475                                              0                 0  \n",
       "5476                                              0                 0  \n",
       "5477                                              0                 0  \n",
       "5478                                              0                 0  \n",
       "5479                                              0                 0  \n",
       "\n",
       "[5480 rows x 147 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_cleaned_old = pd.read_csv('data/data_vectorized_240228.csv')\n",
    "q_cleaned_old.drop(['ia_status_Facility Study', 'ia_status_Feasibility Study',\n",
    "        'ia_status_IA Executed', 'ia_status_Operational',\n",
    "        'ia_status_System Impact Study', 'Unnamed: 0'], axis = 1, inplace=True)\n",
    "q_cleaned_old.drop(['ia_status_Withdrawn'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = q_cleaned_old.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train, feature_names=feature_names, class_names=classes, discretize_continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module): # nn.Module = base case for all neural network modules\n",
    "    # we define model as a subclass of nn.Module -> it creates parameters of the modules with utility methods like eval()\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.flatten = nn.Flatten()\n",
    "            self.linear_relu_stack = nn.Sequential(\n",
    "                nn.Linear(140, int(128)), # apply linear transformation to the incoming data : y = x*W^T+b\n",
    "                                        # weight here will be size of output * input\n",
    "                nn.ReLU(),  # rectified linear unit function: 0 for values < 0 and linear function if > 0\n",
    "                nn.Linear(int(128), int(64)),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64, 32),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(32, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64, 2),\n",
    "            )\n",
    "            #self.sig = nn.Sigmoid() \n",
    "            #self.softmax = nn.Softmax(dim=1)\n",
    "            # TODO: BCELoss does not expect raw logits - every value should be in the range [0,1].\n",
    "            # TODO: Check what the previous model was doing, if there was regularization, learning rate, etc.\n",
    "            \n",
    "        def forward(self, x): \n",
    "            x = self.flatten(x) # collapse into one dimensions\n",
    "            x = self.linear_relu_stack(x)\n",
    "            #x = self.sig(x)\n",
    "            #x = self.softmax(x)\n",
    "            return x # changed to squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(\"model\", \"epoch5.pt\")\n",
    "the_model = NeuralNetwork()\n",
    "the_model = torch.load(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=140, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=32, out_features=64, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=64, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.77818487, -1.09476845, -0.42817022, ..., -0.03576319,\n",
       "        -0.02340396, -0.02340396],\n",
       "       [ 0.9498535 ,  0.53455479, -0.42817022, ..., -0.03576319,\n",
       "        -0.02340396, -0.02340396],\n",
       "       [ 0.9498535 ,  0.86041944,  2.33551976, ..., -0.03576319,\n",
       "        -0.02340396, -0.02340396],\n",
       "       ...,\n",
       "       [-2.85183092, -2.56115936, -0.42817022, ..., -0.03576319,\n",
       "        -0.02340396, -0.02340396],\n",
       "       [-0.60538103, -1.25770077, -0.42817022, ..., -0.03576319,\n",
       "        -0.02340396, -0.02340396],\n",
       "       [ 1.29546117,  1.34921641, -0.42817022, ..., -0.03576319,\n",
       "        -0.02340396, -0.02340396]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "flatten() takes from 0 to 1 positional arguments but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#i = np.random.randint(0, X_test.shape[0])\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m exp \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthe_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\celin\\miniconda3\\envs\\videogpt\\lib\\site-packages\\lime\\lime_tabular.py:355\u001b[0m, in \u001b[0;36mLimeTabularExplainer.explain_instance\u001b[1;34m(self, data_row, predict_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[0;32m    348\u001b[0m     scaled_data \u001b[38;5;241m=\u001b[39m (data \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mmean_) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale_\n\u001b[0;32m    349\u001b[0m distances \u001b[38;5;241m=\u001b[39m sklearn\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mpairwise_distances(\n\u001b[0;32m    350\u001b[0m         scaled_data,\n\u001b[0;32m    351\u001b[0m         scaled_data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    352\u001b[0m         metric\u001b[38;5;241m=\u001b[39mdistance_metric\n\u001b[0;32m    353\u001b[0m )\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m--> 355\u001b[0m yss \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minverse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;66;03m# for classification, the model needs to provide a list of tuples - classes\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;66;03m# along with prediction probabilities\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\celin\\miniconda3\\envs\\videogpt\\lib\\site-packages\\torch\\nn\\modules\\module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[0;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Cell \u001b[1;32mIn[52], line 24\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x): \n\u001b[1;32m---> 24\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# collapse into one dimensions\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_relu_stack(x)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m#x = self.sig(x)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m#x = self.softmax(x)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\celin\\miniconda3\\envs\\videogpt\\lib\\site-packages\\torch\\nn\\modules\\module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[0;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[1;32mc:\\Users\\celin\\miniconda3\\envs\\videogpt\\lib\\site-packages\\torch\\nn\\modules\\flatten.py:40\u001b[0m, in \u001b[0;36mFlatten.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend_dim\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: flatten() takes from 0 to 1 positional arguments but 2 were given"
     ]
    }
   ],
   "source": [
    "#i = np.random.randint(0, X_test.shape[0])\n",
    "exp = explainer.explain_instance(X_test[1], the_model, num_features=2, top_labels=1, num_samples=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videogpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
